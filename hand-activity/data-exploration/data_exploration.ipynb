{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Exploration of hand-activities dataset by Laput and Harrison\n",
    "The research paper describes the data collection process as follows:\n",
    "\n",
    ">We recruited 12 people from a public participant pool\n",
    "(9 female, mean age 26.6), who were compensated $20 for\n",
    "the 90-minute study. Participants were asked to wear our\n",
    "smartwatch on their dominant arm. Once comfortable, the\n",
    "“obstacle course” began. Each “lap” of the course consisted\n",
    "of visiting four stations with physical activities that incorporated the 25 hand activities (random order). Participants\n",
    "performed each hand activity for at least 15 seconds, and\n",
    "they were free to perform them however they saw fit, capturing natural user variation.\n",
    ">\n",
    ">In total, participants completed four laps of our course,\n",
    "with three-minute breaks in between. Tis ensured temporal separation between data collection rounds. Additionally, in between laps three and four, participants were asked\n",
    "to remove and then re-wear the smartwatch, again to capture variation and to mitigate overfiting (common in worn\n",
    "sensing systems). A trained observer labeled data using a\n",
    "laptop interface immediately afer each hand activity was\n",
    "performed. This process yielded 2500 labeled instances per\n",
    "session, per user, resulting in a total of 120K instances.\n",
    "\n",
    "Laput, G. and Harrison, C., 2019, May. Sensing fine-grained hand activity with smartwatches. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (pp. 1-13).\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Structure and size\n",
    "The dataset is quite extensive. The experiments have been done with **12** users over **25** different hand activities.\n",
    "\n",
    "Each user has performed 4 rounds in the obstacle course, rounds 1-3 are done in a similar way. For round 4 each user\n",
    "took his smartwatch off his hand and wore it again.\n",
    "\n",
    "The data is structured in two ways:\n",
    "* Per round\n",
    "* Per user\n",
    "\n",
    "**The raw data is not available! Only the already preprocessed spectrogram.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data\n",
    "The data is available as npy array files, these can be imported in the following way:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31174, 3, 256, 48)\n",
      "(31174,)\n",
      "(31174,)\n",
      "[0 0 0 ... 0 0 0]\n",
      "['Brushing Hair' 'Brushing Hair' 'Brushing Hair' ... 'Brushing Hair'\n",
      " 'Brushing Hair' 'Brushing Hair']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_path = '/mnt/data/hand-activity-data/'\n",
    "round1_x = np.load(data_path + 'rounds/round1_features_X.npy')\n",
    "round1_y = np.load(data_path + 'rounds/round1_features_Y.npy')\n",
    "round1_labels = np.load(data_path + 'rounds/round1_features_labels.npy')\n",
    "\n",
    "print(round1_x.shape)\n",
    "print(round1_y.shape)\n",
    "print(round1_labels.shape)\n",
    "print(round1_y)\n",
    "print(round1_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "As can be seen for each round or user there are three files:\n",
    "* `features_X`: the spectrograms\n",
    "* `features_Y`: the classes [0-24]\n",
    "* `features_labels`: the classes, but written as labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Class distribution\n",
    "The samples are quite equally distributed over the different classes. Per round we have around 1200 samples per class.\n",
    "Which are around the 2500 samples per user per round as described in the paper.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(round1_y, bins=25)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Also the distribution of samples over the different rounds is very similar:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "round1_y = np.load(data_path + 'rounds/round1_features_Y.npy')\n",
    "round2_y = np.load(data_path + 'rounds/round2_features_Y.npy')\n",
    "round3_y = np.load(data_path + 'rounds/round3_features_Y.npy')\n",
    "round4_y = np.load(data_path + 'rounds/round4_features_Y.npy')\n",
    "\n",
    "print('samples in Round 1: {}'.format(round1_y.shape))\n",
    "print('samples in Round 2: {}'.format(round2_y.shape))\n",
    "print('samples in Round 3: {}'.format(round3_y.shape))\n",
    "print('samples in Round 4: {}'.format(round4_y.shape))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples in Round 1: (31174,)\n",
      "samples in Round 2: (31175,)\n",
      "samples in Round 3: (31087,)\n",
      "samples in Round 4: (31203,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Examples of a spectrogram\n",
    "To visualize an example of one of the spectrograms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing spectrogram for:  Brushing Teeth\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=48x256 at 0x7FA26C492FA0>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADAAAAEACAAAAADQZKpCAAAEm0lEQVR4nO2X227cRgyGP0qzazt2ml61yCP0uu/RZ+2j1WmTxuuVphdajv45ab09AEUgwhC0I575kxzbAAECTDDDCDOc/T3AAxzhCA/wCPYDzP55gAkMBjAADKK/LOfhDAMcYIYJAuAqIkQYAIgwLpL3onKEc654hhfnPkIAO4iCwdUksoXJ/4AQcrvRDeInJze1/DRz9SbPZC3ZNNcbfvEQZ8/sq/+d4OTvL3BacvgFvsJX+Ayf4RP8Ds/wCZ7hGX6DP+AzfIET2K9wB/fwzktz78VaCjp6bBHOYD/CAzzAEzzBd/BBnu/hHTzCnQvbe8CDO0BwIBzcwlGiN7CPksRB8r34MMELTHD2jIfldGGdPX3RKz0sgHMLI9id1yVKdZORSWB3QccHDz863yR1neDVDS61Cj95A7x6aRams0ue/XCRCX96uySVkzuGw2GWpx0FW0tjjO60IjK6kXCXp8gEWikNCy0lDwf/EJzJhHVxKcq7BUHv6G6YpHgu4H0QjhRZdPeid7m5V3aAwyIqPWR5yWfP3hnCzx7+2Z+T5H6pCVLs8ORdNsMJxryJVddSR/uYd3MUZ5KpV4fCGewpjTSRHKR2mugLvM0xEyVibRJFSlAgpepqJxVluYxKpALaQMj7ZcwdcqghRSjogqDvBXCKPKReaYyPEAbB9iTZiJ60QQ5t6YcoOtQrRDhl7BJDobhwXXEVcO+RraOsamoAGyUDqQjKmgp3WSjFykHWoVXcBmGuvmkwUx5STB2nweGTJu1FpTAIimbBlU7ObIoeWx/Ic6UMlnZegU3L48lcKvKTFCf31FRQ6XraJQspJUHhkCzE3B+thmn7IjUpKr0G/dhqlyhGYp6PoK4n8PUgaMhtJrYiJrcTlxhiK+70MuRehRRrYVrFTP6CclMBLo251MNW1N/E3SJoSwI1Ux33+jfkfMkOrcNBl2KN51gZv7RooUmf6etajeaULsQ016GYCxpoIUyCd6/GiVUTs7Zo4q6j1zjXwlkrp7Wflq4shXoqVopQC8X1GM9c6mmNVTKsHsal081+oONDlN1XutT2OBdmO4aek+XbBkbYDlqbNpUo6CkthOvkQ6HRs6CurtBIFCumgoJKb7OuLvXSUntrvcI15/nKtq2ydGzsfKCV4pjqQO5DA9X+MzTXQsy5M5d63bxyFD+HiqO3hy6DrFCzgZSYBIqhVBShcNiaWdqYa1bu7ZYzqiWoG8WzGwNVOZsjcO24t6S/PK9XU0/S6DjQFDDkomv5S08sGzPFBKGyXN7IeqzZJTGlst5UTZcCeRF6Auv9qB6VzfZPh+v1J1Fx+7ihgZopvnk/BPpoawKkMSprmY2Qrqyfboc1R8Gb9jQVcK7EcPU6mFmn1d+NwhUy7fNeTzYsXFVfTtGeS92VpeO+KbY9Iq7T7Wi9KlBP/+vct3pRquhq3dhD2dHG+zdC3RT31kUX3jfc7reT+KaqF2W5TceVfzgSZR13E63Tu1b271B2b32rQPtHi7bG/X8b2E7/lK7D4oae5psce3+HTEfinpCddtppp5122mmnnXbaaaeddtppp512+j/QX9wpxBX4Frc2AAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "testsample = 300\n",
    "testaxis = 1\n",
    "\n",
    "data_path = '/mnt/data/hand-activity-data/'\n",
    "user1_x = np.load(data_path + 'users/features/U1_features_X.npy')\n",
    "user1_labels = np.load(data_path + 'users/features/U1_features_labels.npy')\n",
    "\n",
    "print('Showing spectrogram for: ', user1_labels[testsample])\n",
    "\n",
    "example_spectrogram = user1_x[testsample][testaxis]\n",
    "example_spectrogram = example_spectrogram.flatten()\n",
    "example_spectrogram = np.reshape(example_spectrogram, (48,256)).swapaxes(0,1)\n",
    "\n",
    "max = np.max(example_spectrogram)\n",
    "\n",
    "create_grayscale_im = np.vectorize(lambda x: (x / max * 255))\n",
    "grayscale_im = create_grayscale_im(example_spectrogram)\n",
    "grayscale_im = grayscale_im.astype(np.uint8)\n",
    "\n",
    "im = Image.fromarray(grayscale_im)\n",
    "display(im)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wrong coding of the data!!\n",
    "As can be seen in the code above some mistake has been made when saving/creating the spectrograms. While the structure\n",
    "of the data is right 256x48 I assume that at some point somebody flattened the input and put them back into the wrong\n",
    "direction.\n",
    "\n",
    "So far it is unclear to me if the models were also trained with the skewed input or not, but considering the rather\n",
    "good results I would assume that that is not the case. It definitely is something to keep in mind though when we train\n",
    "on this data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}